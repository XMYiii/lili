2.4.6 中断在多处理机(SMP)上的分发
	以前描述的都是单处理机系统上的中断过程，在单处理机的系统中，主PIC（Programmable Interrupt Controller）的输出线直接连接到CPU的INTR引脚。如果系统中有多个CPU，为了充分挖掘SMP体系结构的并行性，如何把中断传递给系统中的每个CPU至关重要。为此，Intel引入了一种名为I/O高级可编程控制器（I/O APIC）的新组件，用以代替老式的8259A可编程中断控制器，此外，Intel当前所有的CPU都含有一个本地APIC，每个本地APIC都有32位的寄存器，一个内部时钟，一个本地定时设备及为本地中断保留的两条额外的IRQ线LINT0和LINT1。所有本地APIC都连到一个外部的I/O APIC，形成一个多APCI系统。
 
图2.10 多级APIC系统
如图2.10所示，一个多APIC系统。一条APIC总线把“前端”I/O APIC连接到本地APIC，来自设备的IRQ线连接到I/O APIC，因此，相对于本地APIC，I/O APCI起路由的作用。在Pentium III的母版和早期的处理器上，APIC总线是一个串行三线总线；从Pentium 4开始，APIC总线通过系统总线来实现。
I/O APIC的组成为：一组24条IRQ线，一张24项的中断重定向表（Interrupt Redirection Table），可编程寄存器，以及通过APIC总线发送和接收APIC信息的一个信息单元。与8259的IRQ引脚不同，中断优先级并不与引脚号相关联，中断重定向表中的每一项都可以被单独编程，以指明中断向量、优先级和目标处理器及选择处理器的方式。重定向表中的信息用于把每个外部的IRQ信号转换为一条消息，然后，通过APIC总线把消息发送给一个或多个本地APIC单元。来自外部硬件设备的中断请求以两种方式在多CPU之间分发：静态分发和动态分发。
1.	静态分发
IRQ信号传递给重定向表相应项中所列出的本地APIC，中断立即传递给一个特定的CPU，或一组CPU，或所有CPU。
2.	动态分发
如果处理器正在执行最低优先级的进程，IRQ信号就传递给这种处理器的本地APIC。每个本地APIC都有一个可编程任务优先级寄存器（Task Priority Register，TPR），TPR用来计算当前运行进程的优先级，Intel希望在操作系统内核中通过每次进程切换对这个寄存器进行修改。
如果两个或多个CPU共享最低优先级，就利用仲裁技术在这些CPU之间分配负荷，在本地APIC的仲裁优先级寄存器中，每个CPU都分配一个0~15范围内的值，每个本地APCI有一个唯一的值。当中断传递给一个CPU时，其相应的仲裁优先级就自动为0，而其它每个CPU的仲裁优先级都加一，当仲裁优先级寄存器大于15时，就把它置为获胜CPU前一个仲裁优先级加一。因此，中断以轮转方式在CPU之间分发。
目前大部分单处理器系统包括一个I/O APIC芯片，可以用一下两种方式对这种芯片进行配置：
1.	作为一种标准8259A方式的外部PIC连接到CPU，本地APIC被禁止，两条LINT0和LINT1分别配置为INTR和NMI引脚。
2.	作为一种标准外部I/O APIC，本地APIC被激活，且所有的外部中断都通过I/O APIC 接收。
在双核CPU系统上，每个核都有一个本地的APIC，中断在各个核之间的分发有点类似SMP的情况。无论是多核CPU还是SMP我们可以通过对ACPI编程，让所有的中断都被一个CPU处理。被那个CPU处理由一个可以修改的变量来控制，这个变量可以通过/procs中的一个文件来修改，系统中有一个后台进程irqbalance定期修改该文件。
2.5 本章总结
本章主要讲述了外设和系统的连接方式，外设与主机的数据交换方式，以及Linux内核对外设中断的响应过程，并讲述了Linux系统对外设中断响应的几种优化，最后阐述了中断在多处理机系统上的处理过程。
三 高速网卡与主机内存的数据交换
3.1 网络接口卡的整体结构
整个以太网卡芯片包括了几个大的模块：PCIE接口及其配置寄存器(CFG)部分；DMA引擎部分，接收和发送FIFO，及以太网MAC协议处理部分和物理层(PHY)模拟信号处理部分。此外，还有一些辅助模块，如EEPROM接口模块，扩展BootROM接口模块，LED控制和整个芯片的命令状态寄存器(CSR)等部分。
 图3.1 网卡硬件结构
如图3.1所示，整个芯片中，PCIE部分主要负责和host端主机进行通讯。DMA模块部分主要负责数据包的具体控制，这包括配合PCIE的控制动作、DMA访问交易的起始地址以及对片内SRAM的各种控制。MAC模块则负责处理以太网CSMA/CD协议，根据这一协议处理网路路径、网络冲突，网路共享以及遵循以太网的各种规则来发送和接收数据包。物理层(PHY)部分则是数模混合电路，具体处理网卡与网卡之间的点对点具体信号的连接以及对信号进行恢复动作，使得恢复的数据能够被MAC部分使用。
网卡芯片的数据通道主要有两路：一路是从host主机根据上层协议，传来的数据包，到达PCIE接口，由TxDMA控制到达TxFIFO先暂存起来，当TxFIFO到达一定门限高度时，就要求TxMAC将TxFIFO中的数据包按照CSMA/CD原则发送到具有自适应选择功能的PHY层，再由双绞线或者光纤发送到外部网络上。另一数据通道就是接收过程，数据在外部网络串行传输，被物理层接收并对信号行恢复处理，将数据转换为并行数据到达接收MAC中，然后MAC判断网络数据包，将数据包写进接收FIFO。当接收FIFO数据接收达到一定门限后，DMA会通过PCIE总线，将数据写入host端的内存，如果接口是PCI总线，DMA引擎还要请求占用总线才能进行DMA传送，而PCIE是点到点的传输方式DMA不需要请求占用总线就能进行DMA传送。
3.2 基于描述符和中断机制的DMA通信
3.2.1 描述符机制
高速网卡以DMA的方式和主机进行通信。在2.3节中我们讲到简单的DMA方式不适合外设和主机进行大量的数据传输，高速网卡采用DMA的链式传输和命令队列传输相结合的机制和主机进行大量的数据交换。我们把包含主机内存地址、字节数和控制信息的一个数据结构称为一个描述符，一个描述符指定了一块主机内存的首地址和这块内存的大小。描述符在主机内存和DMA引擎中的组织如图3.2所示。
 
图3.2 描述符机制
为了方便DMA引擎读取主机内存中的描述符，描述符在内存中往往以队列的形式组织，如图3.2所示，而不是组织成链表的形式，这样DMA引擎就不需要为实现检索链表的功能而设计复杂的逻辑，只需设置几个寄存器用于保存描述符的基地址、个数和DMA引擎下一个要读取的描述符的地址。
在DMA的链式传输中，每一次DMA传输结束，DMA引擎都要从主机内存的描述符缓冲区中读取下一次DMA传输的描述符，为了降低DMA引擎从主机内存中读取描述符的次数，高速网卡采取链式传输和命令队列传输相结合的机制，在DMA引擎中设置缓冲区，用于存放从主机读取的描述符，DMA引擎每次可以读取一定数目的描述符。
DMA引擎包含两个描述符队列即接收描述符队列和发送描述符队列。网络接口卡和主机进行正确数据传送的基本必要条件是接收和发送描述符的正确传送。无论是发送描述符还是接收描述符都涉及到描述符回收问题，为了便于主机和网络接口卡之间协同，描述符的队列结构通常设计成环状，如图3.2所示。描述符队列长度跟描述符个数的设置有关。
可用接收描述符到达DMA引擎可通过两种方法。一种是基于主机的方式，由主机告知DMA引擎此次可用接收描述符的个数，然后DMA引擎通过DMA机制获得新的可用接收描述符，具体实现是在网卡驱动的中断处理程序中，通告DMA引擎可用接收描述符的个数；另一种方法是基于DMA引擎的，由DMA主动请求描述符，如图3.3所示。
 
  图3.3 基于DMA引擎的接收描述符获取方式
在实际的工程实现中，往往采用基于主机和基于DMA引擎相结合的方式。网卡打开时需要主机告诉DMA引擎总的可用接收描述符，主机执行中断处理程序，完成描述符回收后，需要通告DMA引擎回收描述符的个数。为了防止描述符在主机和DMA引擎之间传递丢失，需要DMA引擎主动向主机请求获取描述符，当DMA引擎发现接收描述符队列上的数据小于一定的阈值，而主机仍然没有通告DMA引擎接收描述符可用时，便主动向主机发送中断，请求描述符。
3.2.2 中断机制
网卡硬件通过中断通告主机CPU数据包到达主机内存，CPU在中断中处理程序中处理到达的数据包、回收描述符，并将回收的描述符补充到网卡硬件。中断会带来处理机的额外开销，但中断是软硬件交互的有效手段，因此如何减少中断开销是高速网卡设计中要考虑的一个重要方面。主机在中断处理程序中，通过写网卡硬件寄存器，告诉网卡硬件补充描述符的个数；网卡硬件可以通过回写描述符的方式，通告主机本次中断到达数据包的个数，也可以通过设置寄存器，通过寄存器的值通告主机本次中断，到达数据包的个数。
在吉比特或者10吉比特网络条件下，网络处理开销大小直接影响系统性能[6]。网络处理开销大小取决于网络中断次数、网络数据传输方式以及用户层和操作系统内核间的数据拷贝方式。DMA引擎中断机制决定网络中断次数。为减少报文接收（发送）中断的次数，DMA引擎接收（发送）了一定数量的报文后才置接收（发送）中断。这个固定的报文数量被称为接收（发送）中断阀值。
为避免因网络流量过低导致较长的网络延迟，DMA引擎还提供超时机制。以数据报文接收为例，假设接收中断阀值为s，如果在接收到s个报文前，接收定时器超时，DMA引擎立即产生接收中断。中断阀值与超时相结合的中断机制能够极大地减少网络接口卡产生的中断次数，同时将报文延时控制在较小的范围内。但是，中断阀值和超时值的设置对网络接口卡性能影响很大，如何选择合适的值是需要研究的一个问题。
3.3 数据报文的收发过程
基于DMA机制的网络接口卡的数据接收和发送过程并不是对称的，因此我们将数据的发送和接收过程分开介绍并讨论。
数据报文的接收过程是一个软硬件交互过程，如图3.4所示。1.驱动程序初始化所有可用的接收描述符。然后，驱动程序通告网络接口卡接收描述符在内存的起始地址以及可用接收描述符的个数；2.DMA引擎根据接收描述符的起始地址信息和其他相关信息通过DMA方式将所有可用的接收描述符下载到DMA引擎；3.当有数据报文到达网络接口卡时，DMA引擎就根据接收描述符指示的地址发动一次DMA操作，将到达的数据报文写入主机内存；4.DMA操作完成后，DMA引擎立即发动另一次DMA操作，回写刚才已使用的接收描述符的若干域（报文长度域，回写标志域）；5.当接收报文的数量达到接收中断阀值时，DMA引擎通告主机接收中断，主机处理接收数据并进行接收描述符的回收（当接收报文的数量未达到接收中断阀值但接收定时器超时的情况下，DMA引擎亦通告主机接收中断）；6.主机在完成接收描述符的回收后又将此次处理完成接收描述符个数通告给DMA引擎，DMA引擎根据相关信息读取可用接收描述符。
           
图3.4  数据报文接收过程示意图
数据报文的发送过程也是一个软硬件交互过程，如图3.5所示。1.驱动程序初始化所有可用的发送描述符，同时通告网络接口卡发送描述符的在内存中的起始地址；2.当有数据报文需要发送时，驱动程序将数据报文在内存中的起始地址和报文长度填写到发送描述符的相应域中；3.发送描述符填写完成后，网络接口卡驱动程序就通告网络接口卡此次需要处理的发送描述符个数；4.DMA引擎发动一次DMA操作将需要处理的发送描述符下载到网络接口卡上；5.发送描述符的下载完成后，DMA引擎就根据发送描述符的内容发动DMA操作，将发送描述符指向的数据报文发送到网络上；6.当发送报文的数量达到发送中断阀值时，DMA引擎通告主机发送中断，驱动程序开始进行发送中断的处理，并进行发送描述符的回收（当发送报文的数量未到发送中断的阀值但发送超时的情况下，DMA引擎亦通告主机发送中断）。
 
图3.5 数据报文发送过程示意图
          
3.4 Linux对高速网卡中断的处理
3.4.1 Linux对网卡中断的处理过程
Linux下接收报文的过程如图3.6所示：（1）网络上的报文从网络上到达网卡硬件的缓冲区；网卡硬件DMA引擎从描述符FIFO中取描述符，并根据描述符的地址将网卡硬件缓冲区中的报文DMA到内存；（3）当网卡DMA一定数量的报文或者接收超时，便向主机发硬中断；（4）主机CPU执行硬件中断处理程序将数据包挂着内核网络核心层的接受队列上，并触发软中断处理程序；（5）软中断处理程序对接收队列上的报文进行处理，并根据协议类型将报文放在不同的队列中，如果不是发往本机的报文，软中断处理程序会将报输出到发送队列上。（6）发送硬中断处理程序，通过网卡硬件将发送队列上的报文输出到外部网络上。
 
	图3.6 Linux 对网卡中断的处理过程
在Linux操作系统核心中，网络处理占用CPU资源主要分成两部分：一部分用来处理网卡数据到达而激活的中断；另一部分用来对收到的数据包进行处理、转发。理想状态下，如果网络接受数据与处理数据速率相同。同时接收与处理占用的CPU资源的和小于CPU的总的资源，那么数据包既不会拥塞也不会丢掉，网络性能良好。
但是在高负荷网络中，由于网卡接收数据包是通过中断方式通知CPU的，而这个中断属于硬件中断，比软中断处理程序的优先级高。这样，软中断处理程序会被这个硬中断打断，如果网卡中断过于频繁，硬中断处理程序会一直占用CPU，而软中断处理程序得不到执行，造成接受队列上的报文得不到处理而使报文丢失。如果网络的报文速率一直很高，系统会一直处于这种状态。Mogul和Ramakrishnan称这种状态为“接收活锁”（Receive Live Lock）。当系统发生“接收活锁”时，系统的吞吐率降为零；CPU会一直被硬中断处理程序占用，其它程序无法执行；系统对报文处理的延迟增加。Mogul和Ramakrishnan提出NAPI技术解决系统的“接收活锁”问题。
3.4.2 NAPI技术
Mogul和Ramakrishnan提出在高速网络环境下利用轮询技术可以有效的模仿包处理的Round-Robin调度，及我们通常说的NAPI(New API)技术。在轮询系统中，设备的中断处理程序只是调度轮询线程，记录对处理包的需要并关闭设备中断，然后便从硬中断中返回。但是，返回后它并不打开中断，这就意味着系统不会被后来的接收或者发送中断打扰，直到轮询线程处理了所有待处理的数据包。一旦一个设备上的数据包被处理完，轮询线程便激活设备的中断，从而可以使后续到达的数据包能够产生中断。
系统在启动时，设备驱动在轮询系统中注册自己，提供给轮询系统相应的处理程序，用来处理接收和发送数据包，以及在处理完后关闭中断；同时驱动还需向系统注册设备的硬中断处理程序，以保证在低负荷的网络中采用中断机制。当轮询线程被调用后，它便检查系统中所有注册了的轮询设备，看是否有处理请求，然后激活相应的中断处理程序去处理原始内核中本应由硬中断程序做的事情。
接收包时，接收包处理程序会直接调用上层IP协议处理程序。而不是把报文放在接收队列上等待软中断处理。这就意味着从设备收到的数据包会被尽快的处理，而不会让包现在接收队列中排队，造成包的处理延迟。同时，轮询线程还可以给处理程序赋予包处理个数限制，及处理完限额数目的包后立即返回，而不管是否还有包在等待处理。这种方法保证了多个设备之间做Round-Robin调度，避免了CPU被某个接收处理独占。
 
图3.7 采用NAPI技术转发数据流程
采用NAPI技术后，Linux对数据包的转发过程如图3.7所示。
1.	以太网帧进入网卡，网卡通过DMA将数据包放入主机内存的缓存区，并向系统发中断。
2.	网卡中断处理程序将网卡中断禁止，激活当前处理机的softnet内核线程。
3.	softnet内核线程从接收环中取出一个以太网帧F，送入协议栈中处理，处理内容包括：（1）F经过二层（Ethernet）协议处理的到IP分组P；（2）P被送到IP协议栈处理，如果是送往本地主机的报文，会根据报文类型的不同将P会送往上层不同的协议，如果是送往其它主机的报文，P会被送往驱动的输出队列Q；（3）softnet内核线程依次从Q中取出IP分组，并组装成以太网帧，调用输出设备驱动程序，将以太帧放入设备输出缓冲区。
4.	当softnet内核线程从接收环中取完所有的以太帧后。将网卡中断打开。
5.	网卡在发送完以太网帧后，发出一个中断信息。
6.	网卡的中断处理程序，释放报文缓冲区sk_buffer并将回收的描述符补充到驱动。	
3.4.3 NAPI在SMP上的性能分析
NAPI技术能够提高Linux的网络性能，但其SMP扩展性能却并不好，实验发现两路SMP的性能甚至不如单个处理器（UP）的性能[]。通过对Oprofile性能采集结果的指令集分析和实验发现：Linux的网卡中断次数在各个处理器上分布不均，造成处理机间过多的任务切换，以及Cache“污染”问题，是影响NAPI在SMP系统上的性能不理想的一个重要的原因[]。
前面章节中我们讲到中断在SMP上的分发有静态和动态两种方式，目前Linux系统采用动态分发的方式，这是造成NAPI在SMP系统上性能不理想的根本原因，因此我们可以采取静态分发的方式，提高NAPI在SMP系统上的性能，即我们通常所说的中断亲和（IRQ Affinity）[]机制。所谓中断亲和是指将网卡中断处理程序绑定在某个固定的处理上执行，这样做的好处有：（1）可以根据实际情况对网络I/O进行负载均衡；（2）避免动态负载均衡调度的运算开销；（3）一个接口的IO任务有一个处理器负责处理，可以简化中断和softnet处理，避免一些不必要的同步；（4）避免多个处理器过多的任务切换导致的Cahe“污染”问题。
3.5 提高网络接口卡软硬件交互技术
3.5.1 提高总线的带宽
网卡通过系统总线和主机系统相连，因此总线的带宽的大小直接影响网卡和主机数据交换的性能。目前总线技术已发展到第三代：第一代ISA总线，第二代PCI总线和第三代PCIE总线，随之，也出现了三种不同类型的网卡：ISA网卡、PCI网卡和PCIE网卡。
早期的网卡采用ISA总线接口，称为ISA网卡。ISA总线是一条低速总线，又称第一代总线，它的工作频率是8MHz，通常为16/8位宽，ISA总线由南桥(South Bridge)产生，南桥担当ISA总线控制器以及更快的PCI总线间的接口。ISA网卡采用程序请求I/O方式与CPU进行通信，这种方式的网络传输速率低，最大传输带宽33MB/s，CPU资源占用大。
目前在桌面机上广泛使用的网卡基本上都是基于PCI总线的PCI网卡，PCI总线又称第二代总线，它的主要特点是传输速度高，目前可实现66M的工作频率，在64位总线宽度下可达到突发（Burst）传输速率533MB/s。PCE网卡采用DMA的方式和主机通信，具有数据传输率高，CPU利用率低的特点。
随着第三代总线PCIE总线的出现，基于PCIE总线的PCIE网卡开始出现在服务器和高端的桌面机上。PCIE是一种串行传输总线，单向单线传输速率达到了2.5GB/s，支持多种传输模式，非常灵活（1X、2X…32X），Load/Store架构，与现有的PCI设备100%兼容，支持电源管理、Qos、热插拔，具有容错功能。
3.5.2 减少中断开销
1.	关中断技术
为减少网卡硬件的中断频率，在网卡驱动中采取关中断技术，所谓关中断技术就是当CPU接收到网卡的第一个中断执行中断处理时，在中断处理程序中将网卡的中断关闭，当处理完所有到达的数据包后，在将网卡的中断打开。采取关中断技术的条件是网卡在关中断的条件仍然可以向主机DMA数据。
2.	中断联合技术
硬件为减少中断频率采用“中断联合技术”。所谓“中断联合”就是网络设备DMA完数据后并不立即向系统发中断，而是当设备接收（或者发送）的数据到达一定的阈值后才向系统发中断。网络设备采用“中断联合”技术能大大减少设备送往系统的中断个数，但是会延迟对数据的处理，因为即使数据到达设备，如果个数达不到阈值，设备也不会向系统发中断，系统就无法感知数据的到达。为了克服这个缺点网络设备中引入超时机制，即使设备接收数据包的个数达不到阈值，如果时间超过一定限制，设备也会发中断给系统，通告数据的到达。
3.	零中断技术
大多说操作系统除了采用中断机制外，系统还有一中的方法来检测网卡硬件上数据的到达，那就是轮询，也就是通常我们认为的零中断。系统每隔一定的时间间隔就去检查一次物理设备，若发现设备有数据到达，就去调用相应的处理程序读取数据。在Linux中，轮询可以通过定时器来实现，但该方法存在一个明显的缺点：不管设备是否有数据，系统都要固定的花费CPU的时间去查看设备，且可能延迟对一些紧急数据的处理。但是，轮询方式能够保证在任何情况下收、发包之间公平的得到CPU资源。它与中断驱动技术设计的不同在于：当网络上的数据包到达的频率低而且不可见时，我们可以利用中断来通知CPU数据，从而避免CPU频繁的查询带来的资源浪费；而当网络数据到达频繁时，轮询技术要比中断驱动技术有效的多。
3.5.3 减少上下文切换开销
在中断驱动的系统中，每次网络数据包到达都会引发硬件中断。而每次中断前，如果系统是运行的是用户空间进程，那么就存在用户空间进程到内核空间的切换，在一个重负荷的系统中，频繁的切换开销会浪费系统的资源。我们可以通过开发核心数据流（Kernel-level Streaming）或硬件级流（Hardware-level Streaming）[]的方法来避免系统的切换开销。
核心级数据流是指数据从源经过系统总线进行转发而不需要是数据经过用户空间进程，这个过程因为数据在内存中，因此需要CPU的参与。核心级数据流可以把数据从网络协议栈的接收队列直接拷贝到发送队列，而对数据包的转发对设备是透明的，每个设备并不知道它的数据队列是用户空间进程相连还是与另一个转发设备相连。
硬件级数据流将数据通过私有总线或对等DMA通过系统总线进行转发而不需要使数据经过用户空间进程，也不需要CPU操作数据。在目前的网络系统中我们可以在网卡硬件实现硬件级数据流：在网卡硬件直接判断报文是否是送往本机的报文，若是送往本机的报文，则以DMA的方式交给主机处理，如果是需要转发的报文，则直接将报文从网卡硬件的接收缓冲区以DMA的方式传输到网卡硬件的发送缓冲区，直接在网卡硬件将报文转发而不需要打扰主机，也就是说硬件级数据流的方法对主机是透明的。
3.7 本章总结
本章主要讲述了：（1）高速网卡的硬件结构；（2）网卡与主机的数据交换方式：采用DMA的链式传输和命令队列传输相结合的方式，在实现DMA的链式传输时，需要软件一次性配置所有的DMA命令。我们把包含有DMA目的地物理地址、每次传输的字节数和一些控制信息的DMA命令称为描述符，DMA的链式传输需要描述符机制提供支持才能实现；（2）网卡硬件描述符的获取方式：基于驱动的方式和基于DMA引擎的方式；（3）主机描述符缓冲区和网卡硬件描述符缓冲区的大小模型，以及影响因素；（4）Linux对网卡硬件的中断处理过程；（5）提高软硬件交互技术：提高总线带宽、减少中断开销和减少上下文切换的次数。
