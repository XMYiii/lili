对RDP消息进行代码级的调优
一、优化思路
1.	只考虑优化执行频率比较高的关键路径上的代码。
2.	从Cache利用率角度：提高指令Cache和数据Cache的使用效率。如判断分支调整，数据结构Cache Line对齐等
3.	从减少关键路径上的执行指令数角度：如循环体内固定的计算放在循环体外，尽量使用寄存器、局部变量；集成所有条件一次判断进入高频率分支处理，避免低频率的处理影响性能；将多个位或字节操作合并为长字访问，减少内存操作次数。
4.	充分利用处理器执行的流水线特点，提高执行的并行度，避免内存访问等待。
二、代码级的优化
1、锁，多核最大的痛
目前多核并发的编程中，我们经常要用锁来解决同步和互斥的问题，避免由于多个线程对变量、资源或代码的抢占而引起的各种问题，提高代码执行的正确性和稳定性。但是并行是多核编程追求的目标，加锁保证代码的正确，但影响了我们程序的效率。那么如果我们遇到要加锁的情况，有办法来提高代码的性能吗？
加锁代码的性能取决于两点：a、锁的冲突概率；b、加解锁之间代码的执行时间。
 提高锁的性能可以考虑以下几个办法：
（1）考虑不用锁，典型情况是给每个CPU分配内存；
（2）自旋锁改读写锁，典型情况是数据平面读配置，控制平面偶尔改配置；
（3）大锁变小锁，典型情况是对链表的操作；
（4）将锁变为原子变量，典型情况是保护数据只是几个ULONG；
（5）尽量减少加减锁之间的代码操作。
2、内存访问优化
提高Cache命中优化
当访问内存数据时，CPU会自动预取前后Cache Line长度(64字节)的数据到Cache中。这样，若按流程处理顺序设置数据结构，将会提高处理性能。
避免跨line内存操作
内存操作不要跨页、跨cache line。X86大部分的cpu的cache line长度是64bytes，内存访问不应跨越64 bytes边界。跨line操作将导致2次以上的cache line回写，或内存读取。最差的情况将比最好的情况慢4倍速度。这要求我们在定义数据类型(如端口属性表、路由节点表等)时尽量做到64字节边界对齐。
x86 Cache预取优化
一个存取指令，如果存取的数据不在cache中则需要耗费180个cycle，如果此数据在3级cache中，只需40个cycle，如果在2级cache中则只需10个cycle，如果在1级cache中则只需4个cycle。所以最大限度的减少cache miss可以显著提高系统的性能。一般来说，数据预取在循环里面用的比较多，因为循环是最符合空间局部性的代码。可以在上一次队列调度时同时读取下一个消息，进而在正常数据报文处理的同时进行下一个数据报文和GIB表记录的预取，从而减少内存访问的时间消耗。
3、分支预测优化
代码在内存里面是顺序排列的。对于分支程序来说，如果分支语句之后的代码有更大的执行几率， 那么就可以减少跳转，一般CPU都有指令预取功能，这样可以提高指令预取命中的几率。
4、减少重复处理
加减乘除优化，变量优化，函数优化
