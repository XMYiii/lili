第二章 网络适配器软硬件交互技术
2.2 I/O设备与存储器通信的方式
CPU与“外部世界”通过微机接口（Interface）交换信息，接口是CPU与外界信息交换的中转站。这里所说的“外部世界”，是指除CPU本身以外的所有设备或电路，包括存储器、I/O设备、控制设备、测量设备、多媒体设备、A/D与D/A转换器等。
微机与外部设备之间的数据传送实际上是CPU与接口之间的数据传送，传送的方式不同，CPU对外设的控制方式也不同，从而使接口电路的结构及功能也不同。在微机中，传送数据一般有三种方式：程序方式、中断方式和DMA方式。
2.2.1程序方式
程序方式传送是指在程序控制下进行信息传送，又分为无条件方式和条件传送方式。
无条件传送是指：如果程序员能够确信一个外设已经准备就绪，那就不必查询外设的态而进行信息传输。外设准备就绪是指：对于输入设备，它已经把数据放入接口电路的数据输入端口（数据输入寄存器），CPU可以读取；对于输出设备，它已经准备好接收数据（接口电路的数据输出寄存器已空），CPU可以向它输出数据。由于不查询外设状态，接口电路不需要状态寄存器，只需要数据输入寄存器和数据输出寄存器。
条件传送方式又称为查询方式（polling），CPU从接口电路的状态寄存器读取外设的状态，当外设准备好，则与外设传送数据，否则，应继续查询状态。查询式传送的接口电路除了需要数据端口外，还需要状态端口。
2.2.2中断方式
使用查询方式时，CPU读取状态寄存器并检测状态字，如设备未准备好，CPU不断地查询（读取状态寄存器并检测状态字），浪费了大量CPU时间。使用中断方式，CPU不查询设备状态，当设备准备好时，主动向CPU提出中断请求，CPU响应中断后，在中断处理程序中与设备交换信息。如果设备未准备好，CPU可以执行其他程序，大大提高了CPU的利用率。在每条指令执行完后，CPU均可响应中断，因此，当设备准备好时，CPU可以及时与设备交换信息，大大提高了CPU对设备响应的实时性。因此，中断方式被广泛使用。
在微机中，有多个设备向CPU申请中断，CPU用中断类型码来区分这些设备。一般由专用的中断控制器（Intel 8259）管理多个中断和产生类型码，中断控制器一般位于系统的南桥或者北桥。接口中断请求INT应接至中断控制器的输入，由中断控制器直接向CPU申请中断。
2.2.2 DMA方式
中断方式较之查询方式来说，可以提高CPU的利用率和保证对外设响应的实时性，但对于高速外设（如磁盘、高速网卡等），中断方式不能满足数据传输速度的要求。因为，中断方式下，每次中断均需保存断点（返回地址）和现场（各寄存器的值，包括标志寄存器），中断返回时，要恢复断点和现场。同时，进入中断和从中断返回均使CPU指令队列被清除。所有这些原因，使得中断方式难以满足高速外设对传输速度的要求。对于高速外设的数据传输，一种有效的方式是使用DMA方式。
DMA（Direct Memory Access）技术是一种代替微处理器完成存储器与外部设备或存储器之间大量数据传送的方法，也称直接存储器存取方法。利用DMA技术则可不用CPU介入就能实现外设与内存之间数据的直接传送。DMA的主要优点是当需要把一个外设的大量数据送到指定内存时，它可以自动完成传送任务，也就是说外设发出一个DMA请求，则DMA电路暂停CPU的操作，并控制外设与内存之间进行一次传数，然后再让CPU继续执行程序，这样就使CPU节省了大量对外设的查询时间，从而提高了系统的整体性能。
2.3 高级DMA技术
采用DMA技术在主机内存和外设之间交换数据的条件是数据在主机内存中必须是连续存放的，在DMA传输前由CPU对DMA控制器（DMAC）初始化，告诉DMAC主存的地址和传输的字节数，DMAC完成传输后向CPU发送中断，告诉主机传输结束。如果数据在内存中是以不连续的数据块的形式存在（比如主机内存中的网络数据包），每块数据传输前都要CPU对DMAC进行初始化，DMAC在完成每块数据传输后都需要中断主机，CPU在中断响应中对DMAC进行初始化，下次DMA传输才能继续，因为中断响应实际上是一个软件程序执行过程，如果软件执行时间过长而第二块数据需要很快得到响应，就可能导致丢失数据的后果。
为进一步减轻CPU介入数据交换带来的负担，防止数据丢失，人们提出DMA控制器向智能化方向发展，所谓DMA控制器的智能化是指多个操作命令和参数存放在DMAC内部缓冲队列内或DMAC 外部的存储器中。在实际运用中，这些操作命令和参数规定的可能是多个1/0端口设备按照一定的顺序和存储器进行数据交换，也可能是不同存储区域内数据的非连续交换。当DMA接收到一个有效的DMA请求后将依次读取这些操作命令和参数，并执行这些命令和参数规定的数据传输操作。完成所有的数据传输后DMA产生一个中断信号。CPU只需初始化这些命令和参数，接收DMA最后产生的中断信号，从而无需在DMA进行数据传输过程时介入。这样大大减轻了CPU对数据传输的介入程度，提高的CPU对其它工作的处理效率。基于这种思想，人们提出了DMA的链式传输方式和命令队列传输方式。
2.3.1 DMA的链式传输方式
链式传输方式的定义：DMA的通道参数（源基地址、目标基地址、数据传输量、下一次描述符指针及其它参数，一组参数称为一个描述符）放在DMAC外的主存内，当前DMA过程完成后DMAC从指针寄存器指向的地址中把新的通道参数读入DMAC内，按照新的参数要求进行新的DMA传输过程。由于这些通道参数放在不同的(或相同的)存储区内，上一组通道参数指出下一组通道参数的存放位置，好像链子联接起来一般，如图2.3所示，故称为链式传输方式。CPU完成这些参数链的初始化后，只要DMAC接到一个有效的DMA请求，DMA将反复进行“一个DMA过程→取通道参数”操作，直到最后一个描述符要求的DMA过程传输完成。
 
图2.3 DMA的链式传输
DMA链式传输的优缺点：DMA的通道参数以链表的形式在内存中组织，链表长度不受限制，可以方便的对描述符链表进行增加和删除，缺点是要求DMAC具有检索链表的功能，DMAC的设计较复杂，实现难度大。在实际应用中通道参数往往以队列的形式在内存中组织，如图2.4所示，这样简化了DMAC的设计，只需设置通道参数基地址寄存器和通道参数个数寄存器便能方便的对整个通道参数进行检索，缺点是通道参数的个数一旦设定便不能被修改。
 
图2.4 DMA的队列传输
2.3.2 DMA的命令队列传输方式
命令队列方式借鉴了链式传输方式处理数据空间续非连续交换的方法，它的实质依然是链式传输方式。但与链式传输方式不同的是，命令队列方式的通道参数没有存放在存储器内，而是直接放置在DMA控制器内部。也就是说，一个DMA控制器内可以存放多个DMA命令，每一个DMA命令指向的设备或存储区可以不相同；当一个请求发生后，DMA控制器将依次执行这些命令，从而完成数据空间的非连续传输。
命令队列传输方式的优缺点：通道参数直接放在DMAC内部，每次DMA操作前不需要从主机内存中读取新的通道参数，执行速度快；但增加了DMAC的面积，提高了设计成本。
2.4 LINUX的中断处理
2.4.1 中断描述符表
中断描述符表（Interrupt Descriptor Table ,IDT）是一个系统表，它与每个中断或异常向量相联系，每个向量在表中有相应的中断或异常处理程序的入口，由idtr CPU寄存器指定IDT在内存中的物理地址。IDT表的每一个表项称为一个描述符，每个描述符8字节，IDT包含三种类型的描述符：任务门（Task gate）、中断门（Interrupt gate）、陷阱门（Trap gate），如图2.5所示。
 
图2.5描述符
任务门：当中断信号发生时，必须取代当前进程的那个进程的TSS选择符放在任务门中，Linux没有使用任务门。
中断门：包含段选择符和中断或异常处理程序的段内偏移量。当控制权转移到一个合适的段时，处理器清IF标志，从而关闭将来会发生的可屏蔽中断。
陷阱门：与中断门相似，但控制权传递到一个合适的段时处理器不修改IF标志，也就是说通过中断门执行中断处理程序时CPU处于关中断状态，而通过陷阱门执行程序时CPU处于开中断状态。
Linux内核在初始化阶段完成了对页式虚拟管理的初始化以后，便调用trap_init()和init_IRQ()两个函数进行中断机制的初始化。其中trap_init()主要是对一些系统保留的中断向量的初始化，而init_IRQ()则主要是用于外设的中断。
2.4.2与硬中断相关的数据结构
i386体系支持256个中断向量，扣除为CPU保留的向量，Linux作为通用操作系统，很难说剩下的中断向量是否够用。所以，在Linux系统中，为每个中断向量设置一个队列，而根据每个中断源所使用的中断向量，将其中断服务程序挂到相应的队列中。
通用中断门是让多个中断源共用的，而且允许这种共用的结构在系统运行的过程中动态的改变，所以在IDT的初始化阶段只是为每个中断向量准备一个中断请求队列，从而形成一个中断请求对列的数组，就是数组irq_desc[]。如图2.6所示描述和与硬中断相关的三个数据结构struct hw_interrupt_type、struct irqaction、struct irq_desc_t之间的关系。
 
图2.6 与硬中断相关的数据结构
中断请求队列头部的数据结构是在include/linux/irq.h中定义的。每个队列头中，用指针action来维持一个由中断服务程序描述项构成的单链表，还有一个指针handler指向另一个数据结构hw_interrupt_type。Hw_interrupt_type中的一些函数指针，用于该队列的，而不是用于具体的中断源的服务。三个数据结构成员的具体说明如下：
struct irqaction结构,它包含了内核接收到特定IRQ之后应该采取的操作，其成员定义如下：
	handler：指向某个函数的指针。该函数就是所在结构对相应的中断处理函数。通过函数int request_irq(unsigned int irq, irqreturn_t(*handler)(int, void *,struct pt_regs *),unsigned long flages, const char *dev_name, void *dev_id )，向系统注册中断处理函数。
	flags：取值只有SA_INTERRUPT（中断可嵌套），SA_SAMPLE_RANDOM（这个中断是源于物理随机性的）和SA_SHIRQ（这个IRQ和其它struct irqaction共享）。
	mask：在x86或者体系结构无关的代码中不会使用（除非将其设置为0）；只有在SPARC64的移植版本中要跟踪有关软盘的信息时才会使用它。
	name：产生中断的硬件设备的名字。因为不止一个硬件可以共享一个IRQ
	dev_id：标识硬件类型的一个唯一的ID。Linux支持的所有硬件设备的每一种类型，都有一个由制造厂商定义的设备ID。
	next：如果IRQ是共享的，那么这就是指向队列中下一个struct irqaction结构的指针。通常情况下，IRQ不是共享的，因此这个成员就为空。
struct hw_interrupt_type结构，它是一个抽象的中断控制器。这包含一系列的指向函数的指针，这些函数处理控制器特有的操作：
	type name：控制器的名字。
	startup：允许从给定的控制器的IRQ所产生的事件。
	shutdown：禁止从给定的控制器的IRQ所产生的事件。
	handle：根据提供给该函数的IRQ，处理唯一的中断。
	enable和disable：这两个函数基本上和startup和shutdown相同。
	数据结构struct irq_desc_t，它具有如下成员：
	status：一个整数。代表IRQ的状态：IRQ是否被禁止了，有关IRQ的设备当前是否正被自动检测，等等。
	handler：指向hw_interrupt_type的指针。
	action：指向irqaction结构组成的队列的头。正常情况下每个IRQ只有一个操作，因此链接列表的正常长度是1（或者0）。但是，如果IRQ被两个或者多个设备所共享，那么这个队列中就有多个操作。
	depth：irq_desc_t的当前用户的个数。主要是用来保证在中断处理过程中IRQ不会被禁止。
irq_desc是irq_desc_t 类型的数组。对于每一个IRQ都有一个数组入口，即数组把每一个IRQ映射到和它相关的处理程序和irq_desc_t中的其它信息。
2.4.3 Linux 的中断处理过程
Linux系统对外部设备的中断处理，是系统的软硬件协同工作的过程，如图2.7所示。硬件负责响应外部设备中断，从中断控制器中读取中断类型码，保存部分CPU寄存器，并使系统跳转到中断服务总程序执行；软件负责将中断号、和中断程序使用到的硬件没有保存的CPU寄存器入栈，从irq_desc结构中找到响应的中断处理程序。
		 
图2.7 Linux的中断处理过程
系统硬件对中断的处理过程：
1.	当执行了一条指令后，cs和eip这对寄存器包含下一条将要执行的指令的逻辑地址。在处理这条指令之前，控制单元会检查在运行前一条指令时是否已经发生了一个中断，如果发生了中断，那么控制单元将从中断控制器8259读取中断号i，保存在CPU的暂时寄存器中。
2.	读取由idtr寄存器指向的IDT表中的第i项中断描述符，并根据该中断描述符中的段选择符在GDT/LDT中取得该中断描述符指定的中断处理程序所在段的基地址，如图2.8所示。
3.	进行特权级检查，首先将当前特权级CPL（存放在cs寄存器的低两位）与段描述符的描述符特权级DPL比较，判断中断前系统是处于核内还是核外。如果CPL小于DPL，就产生一个通用保护异常，因为中断处理程序的特权级不能小于引起中断的程序的特权级。
4.	检查是否发生了特权级的变化，也就是说CPL和所选择的段描述符的DPL是否不同，如果是，控制单元执行如下动作：读tr寄存器以访问运行进程的TSS段，用与新特权级相关的栈段和栈指针的正确值装载ss和esp寄存器，在新的栈中保存ss和esp以前的值。
5.	转载cs和eip寄存器，其值分别是IDT表中第i项中断描述符的段选择符和偏移量字段，这些值给出了中断处理程序第一条指令的逻辑地址，由此转入软件的处理过程。
 
图2.8 硬件对中断的处理过程
系统软件对中断的处理过程：
1.	中断处理程序执行的第一个函数是IRQn_interrupt,它的地址保存在IDT表中的中断描述符中。IRQn_interrupt执行的第一条指令是push $n-256，将中断号减256得到的值保存入栈，然后jump common_intrrrupt。
2.	函数common_intrrrupt的功能：第一步是SAVE_ALL把中断处理程序用到的所有CPU寄存器入栈，但eflage、cs、eip、ss及esp除外，因为这几个寄存器已经由控制单元自动保存；第二步是call do_IRQ;第三步是jmp $ret_from_intr，执行中断返回过程。
3.	do_IRQ做的第一件事情是应答中断，这样中断控制器就可以继续处理其它的事情了。然后该函数对于给定的IRQ号获得一个自旋锁，这样就阻止了其它CPU处理这个IRQ。接着清除几个状态位，然后通过传递过来的IRQ向量检索irq_desc[]数组，如图所示，找出IRQ的处理程序，如果没有处理程序注册，就什么也不做，否则函数handle_IRQ_event被执行，以便实际调用处理程序，在do_IRQ函数返回前会调用do_softirq检查推迟的内核函数是否在等待执行，如软中断、工作队列及下半部。Do_IRQ函数是以禁止本地中断运行的，事实上CPU的控制单元自动清eflages寄存器的IF标志，因为中断处理程序是通过IDT中断门调用的。
4.	handle_IRQ_event的功能：第一步，开中断，允许中断嵌套执行；第二步，调用具体的处理程序执行；第三步，关中断，使中断返回在中断禁止下进行。
执行ret_from_intr执行中断返回过程。
系统中断返回过程：
 
图2.9 中断返回过程
1.	中断返回过程如图2.9，首先判断进入中断前是用户空间还是系统空间，如果进入中断前是系统空间，则直接调用 RESTORE_ALL将堆栈中的寄存器恢复。
2.	如果进入中断前是用户空间，则可能需要进行一次调度；如果不调度，则可有信号需要处理；最后，还是走到 RESTORE_ALL。
3.	最后，调用 iret 指令，使 CPU 从中断返回。
2.4.4 Bottom Half处理机制
中断处理的一个主要问题是怎样在处理例程内完成耗时的任务。响应一次设备中断需要完成一定数量的工作，但是中断处理例程需要尽快结束而不能使中断阻塞的时间过长，这两个需求（工作和速度）彼此冲突，让驱动程序的作者多少有点困扰。
Linux通过将中断处理例程分成两个部分来解决这个问题。称为“顶半部”的部分，是实际响应中断的例程，也就是request_irq注册的中断例程；而所谓的“底半部”是一个被顶半部调度，并在稍后更安全的时间内执行的例程。Linux把中断分成“顶半部”和“底半部”主要处于以下几种情况考虑。
1.	把中断的总延迟时间最小化。Linux内核定义了两种类型的中断，快速的和慢速的，这两者之间的一个区别是慢速中断自身还可以被中断，而快速中断则不能。因此，当处理快速中断时，如果有其它中断到达；不管是快速中断还是慢速中断，它们都必须等待。为了尽可能快地处理这些其它的中断，内核就需要尽可能地将处理延迟到下半部分执行。
2.	当内核执行上半部分时，正在服务的这个特殊IRQ将会被可编程中断控制器禁止，于是，连接在同一个IRQ上的其它设备就只有等到该中断被处理完毕后才能发出IRQ请求。而采用Bottom_half机制后，不需要立即处理的部分就可以放在下半部分处理，从而，加快了处理机对外部设备中断请求的响应速度。
3.	处理程序的下半部分还可以包含一些并非每次中断都必须处理的操作；对这些操作，内核可以在一系列设备中断之后集中处理一次就可以了。即在这种情况下，每次都执行并非必要的操作完全是一种浪费，而采用Bottom_half机制后，可以稍稍延迟并在后来只执行一次就行了。
顶半部处理例程和底半部处理例程之间最大的不同，就是当地半部处理例程执行时，所有的中断都是打开的-这就是所谓的更安全的时间内运行。典型的情况是顶半部保存设备的数据到一个设备特定的缓冲区并调度它的底半部，然后退出，这个操作时非常快的。然后。底半部执行其他必要的工作。例如唤醒进程、启动另外的I/O操作等等。Linux实现下半部的机制主要有tasklet和工作队列。
Tasklet是一个可以在由系统决定的安全时刻在软件中断上下文被调度运行的特殊函数。它们可以被多次调度运行，但tasklet的调度并不会被累积；也就是说，实际只会运行一次，即使在激活tasklet的运行之前重复请求该tasklet的运行也是这样。不会有同一个tasklet的多个实例并行运行，因为它们只运行一次，但是tasklet可以与其它的tasklet并行的运行在对称多处理机（SMP）系统上。Tasklet 可确保和第一次调度它们的函数运行在同样的CPU上。
Tasklet 以数据结构的形式存在，并在使用之前初始化。调用特定的函数或者宏来声明该结构，即可完成tasklet的初始化：
#include <linux/interrupt.h>
struct tasklet_struct{
 void (*func)(unsigned long);
 unsigned long data;}
void my_tasklet_func(unsigned long); //定义一个处理函数
/*定义一个tasklet结构my_tasklet,并与my_tasklet_func(data)函数相关联*/
DECLARE_TASKLET(my_tasklet,my_tasklet_func,data);  
/*与DECLARE_TASKLET类似，但等待tasklet被使能*/
DECLARE_TASKLET_DISABLED(name,function,data); 
tasklet_enable(struct tasklet_struct *); //使能tasklet 
tasklet_disble(struct tasklet_struct *); //禁用tasklet 
tasklet_init(struct tasklet_struct *,void (*func)(unsigned long),unsigned long); 
tasklet_kill(struct tasklet_struct *); // 清除指定tasklet的可调度位
tasklet_schedule(&my_tasklet);//调度tasklet运行
工作队列会在将来某个时间、在某个特殊的工作进程的上下文中调用一个函数。因为工作队列函数运行在进程上下文中，因此可以休眠，但我们不能在工作队列向用户空间复制数据。工作队列类似于tasklet，但两者之间存在非常重要的区别，其中包括：
1.	tasklet在软件中断上下文中运行，因此，所有的tasklet代码都必须是原子的。相反，工作队列函数在一个特殊内核进程的上下文运行，因此它们具有更好的灵活性，尤其是工作队列函数可以休眠。
2.	tasklet始终运行在被初始提交的同一处理器上，但这只是工作队列的默认方式。
3.	内核代码可以请求工作队列函数的执行延迟给定的时间间隔。
工作队列有struct workqueue_strcut 的类型，该结构在<linux/workqueue.h>中定义，在使用之前必须显示的创建一个工作队列，对工作队列初始化和操作的函数如下：
/*step1: 显示创建工作队列*/
Struct workqueue_struct *create_workqueue(const char *name)
Struct workqueue_struct *create_singlethread_workqueue(const char *name)
/*step2: 填充工作队列，将工作队列函数挂着工作队列上*/
INIT_WORK(struct work_strcut *work, viod(*func)(void *), void *data)
/*step3: 调度工作队列执行*/
int queue_work(struct work_queue_struct *queue , struct work_struct *work)
int queue_delayed_work(struct work_queue_struct *queue , struct work_struct *work)
/*step4: 撤销工作队列*/
void destroy_workqueue(struct workqueue_struct *queue)

2.4.5 软中断请求机制
中断服务程序往往都是在CPU关中断的条件下执行的，以避免中断嵌套而使控制复杂化。但是CPU关中断的时间不能太长，否则容易丢失中断信号。为此，Linux将中断服务程序一分为二，各称作“顶半部”和“底半部”。前者通常对时间要求较为严格，必须在中断请求发生后立即或至少在一定的时间限制内完成。因此为了保证这种处理能原子地完成，顶半部通常是在CPU关中断的条件下执行的。具体地说，顶半部的范围包括：从在IDT中登记的中断入口函数一直到驱动程序注册在中断服务队列中的ISR。而底半部则是顶半部根据需要来调度执行的，这些操作允许延迟到稍后执行，它的时间要求并不严格，因此它通常是在CPU开中断的条件下执行的。 
但是，Linux的这种Bottom Half（一下简称BH）机制有两个缺点：（1）在任意一时刻，系统只能有一个CPU可以执行BH代码，以防止两个或多个CPU同时来执行Bottom Half函数而相互干扰。因此BH代码的执行是严格“串行化”的。（2）BH函数不允许嵌套。这两个缺点在单CPU系统中是无关紧要的，但在SMP系统中却是非常致命的。因为BH机制的严格串行化执行显然没有充分利用SMP系统的多CPU特点。为此，Linux2.4内核在BH机制的基础上进行了扩展，这就是所谓的“软中断请求”（softirq）机制。 
Linux的softirq机制是与SMP紧密不可分的。为此，整个softirq机制的设计与实现中自始自终都贯彻了一个思想：“谁触发，谁执行”（Who marks，Who runs），也即触发软中断的那个CPU负责执行它所触发的软中断，而且每个CPU都由它自己的软中断触发与控制机制。这个设计思想也使得softirq机制充分利用了SMP系统的性能和特点。
软中断相关的关键内核数据结构和函数：
Linux在include/linux/interrupt.h头文件中定义了数据结构softirq_action，来描述一个软中断请求，称为软中断描述符，如下所示：
/* softirq mask and active fields moved to irq_cpustat_t in 
* asm/hardirq.h to get better cache usage. KAO 
*/ 
struct softirq_action 
{ 
void (*action)(struct softirq_action *); 
void *data; 
}; 
其中，函数指针action指向软中断请求的服务函数，而指针data则指向由服务函数自行解释的数据
基于上述软中断描述符，Linux在kernel/softirq.c文件中定义了一个全局的softirq_vec[32]数组：
static struct softirq_action softirq_vec[32] __cacheline_aligned;  
在这里系统一共定义了32个软中断请求描述符。软中断向量i（0≤i≤31）所对应的软中断请求描述符就是softirq_vec［i］。这个数组是个系统全局数组，也即它被所有的CPU所共享。在软中断向量0～31中，Linux内核仅仅使用了软中断向量0～3，其余被留待系统以后扩展。Linux在头文件include/linux/interrupt.h中对软中断向量0～3进行了预定义：


/* PLEASE, avoid to allocate new softirqs, if you need not _really_ high frequency threaded job scheduling. For almost all the purposes tasklets are more than enough. */ 
enum 
{ 
HI_SOFTIRQ=0, 
NET_TX_SOFTIRQ, 
NET_RX_SOFTIRQ, 
TASKLET_SOFTIRQ 
}; 
其中，软中断向量0（即HI_SOFTIRQ）用于实现高优先级的软中断，软中断向量1和2则分别用于网络数据的发送与接收。软中断向量3（即TASKLET_SOFTIRQ）则用于实现诸如tasklet这样的一般性软中断。
要实现“谁触发，谁执行”的思想，就必须为每个CPU都定义它自己的触发和控制变量。为此，Linux在include/asm-i386/hardirq.h头文件中定义了数据结构irq_cpustat_t来描述一个CPU的中断统计信息，其中就有用于触发和控制软中断的成员变量。数据结构irq_cpustat_t的定义如下：
/* entry.S is sensitive to the offsets of these fields */ 
typedef struct { 
unsigned int __softirq_active; 
unsigned int __softirq_mask; 
unsigned int __local_irq_count; 
unsigned int __local_bh_count; //标识当前CPU是否处在软中断服务状态
unsigned int __syscall_count; 
unsigned int __nmi_count; /* arch dependent */ 
} ____cacheline_aligned irq_cpustat_t; 
结构中每一个成员都是一个32位的无符号整数。其中__softirq_active和__softirq_mask就是用于触发和控制软中断的成员变量。 
	__softirq_active变量：32位的无符号整数，表示软中断向量0～31的状态。如果bit［i］（0≤i≤31）为1，则表示软中断向量i在某个CPU上已经被触发而处于active状态；为0表示处于非活跃状态。
	__softirq_mask变量：32位的无符号整数，软中断向量的屏蔽掩码。如果bit［i］（0≤i≤31）为1，则表示使能（enable）软中断向量i，为0表示该软中断向量被禁止（disabled）。
根据系统中当前的CPU个数（由宏NR_CPUS表示），Linux在kernel/softirq.c文件中为每个CPU都定义了它自己的中断统计信息结构，如下：
irq_cpustat_t irq_stat[NR_CPUS];
对这些数据结构操作的函数如下：
/*函数open_softirq()初始化软中断向量nr所对应的软中断描述符softirq_vec［nr］*/
void open_softirq(int nr, void (*action)(struct softirq_action*), void *data)
/*函数raise_softirq()在处理器上触发软中断向量nr*/
static inline void raise_softirq(int nr)
/*函数do_softirq()负责执行数组softirq_vec［32］中设置的软中断服务函数*/
asmlinkage void do_softirq()
	函数open_softirq()主要做两件事情：（1）初始化设置软中断向量nr所对应的软中断描述符softirq_vec［nr］。（2）将所有CPU的软中断屏蔽掩码变量__softirq_mask中的对应位设置为1，以使能该软中断向量。
	函数do_softirq()首先调用宏in_interrupt()来检测当前CPU此次是否已经处于中断服务中，如果处于中断服务中函数do_softirq返回；然后根据变量__softirq_active和__softirq_mask调度所有需要执行的函数执行。








